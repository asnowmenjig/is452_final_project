{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: split into lines\n",
      "There are 137 pages and 670 Shakespeare citations in the A section.\n",
      "There are 122 pages and 1082 Shakespeare citations in the B section.\n",
      "There are 218 pages and 1545 Shakespeare citations in the C section.\n",
      "There are 138 pages and 891 Shakespeare citations in the D section.\n",
      "There are 91 pages and 533 Shakespeare citations in the E section.\n",
      "There are 122 pages and 989 Shakespeare citations in the F section.\n",
      "There are 77 pages and 653 Shakespeare citations in the G section.\n",
      "There are 81 pages and 776 Shakespeare citations in the H section.\n",
      "There are 110 pages and 667 Shakespeare citations in the I section.\n",
      "There are 14 pages and 138 Shakespeare citations in the K section.\n"
     ]
    }
   ],
   "source": [
    "#VOLUME 1 (file: johnson_v1_tester.txt)\n",
    "# Dictionary content starts on line 1\n",
    "# A = lines 1 to 26016\n",
    "# B = lines 26017 to 49540\n",
    "# C = lines 49541 to 91532\n",
    "# D = lines 91533 to 117507\n",
    "# E = lines 117508 to 134580\n",
    "# F = lines 134581 to 157822\n",
    "# G = lines 157823 to 172405\n",
    "# H = lines 172406 to 187755\n",
    "# IJ = lines 187756 to 208708\n",
    "# K = lines 208709 to 211203\n",
    "\n",
    "##### PROGRAM FOR VOLUME 1 #####\n",
    "\n",
    "print(\"Executing...\")\n",
    "\n",
    "import string\n",
    "\n",
    "def clean_line(line_str):\n",
    "    cleanline = line_str.lower()\n",
    "    for punc in string.punctuation:\n",
    "         cleanline = cleanline.replace(punc, \"\")\n",
    "    cleanline = cleanline.replace('xc2xb', \"o\")\n",
    "    cleanline = cleanline.replace(\"xc2xba\", \"o\")\n",
    "    cleanline = cleanline.replace(\"xc3x97\", \"x\")\n",
    "    cleanline = cleanline.replace(\"xc3xa\", \"a\")\n",
    "    cleanline = cleanline.replace(\"xc3xa1\", 'a')\n",
    "    cleanline = cleanline.replace('xc3xa2', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa4', 'a')\n",
    "    cleanline = cleanline.replace('xc4x83', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa3', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa5', 'a')\n",
    "    cleanline = cleanline.replace('xc4x81', 'a')\n",
    "    cleanline = cleanline.replace('xc4x85', 'a')\n",
    "    cleanline = cleanline.replace('xc4x87', 'c')\n",
    "    cleanline = cleanline.replace('xc4x8d', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa7', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa8', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa9', 'e')\n",
    "    cleanline = cleanline.replace('xc3xab', 'e')\n",
    "    cleanline = cleanline.replace('xc4x93', 'e')\n",
    "    cleanline = cleanline.replace('xc4x99', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa', 'e')\n",
    "    cleanline = cleanline.replace('xc4x9f', 'g')\n",
    "    cleanline = cleanline.replace('xc3xad', 'i')\n",
    "    cleanline = cleanline.replace('xc3xac', 'i')\n",
    "    cleanline = cleanline.replace('xc5x84', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb1', 'n')\n",
    "    cleanline = cleanline.replace('xc5x88', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb3', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb6', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb8', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb2', 'o')\n",
    "    cleanline = cleanline.replace('xc5x99', 'r')\n",
    "    cleanline = cleanline.replace('xc5xa1', 's')\n",
    "    cleanline = cleanline.replace('xc5xbf', 's')\n",
    "    cleanline = cleanline.replace('xc5x9b', 's')\n",
    "    cleanline = cleanline.replace('xc5x9f', 's')\n",
    "    cleanline = cleanline.replace('xc5xa3', 't')\n",
    "    cleanline = cleanline.replace('xc3xbc', 'u')\n",
    "    cleanline = cleanline.replace('xc3xba', 'u')\n",
    "    cleanline = cleanline.replace('xc5xab', 'u')\n",
    "    cleanline = cleanline.replace('xc5xba', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbc', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbe', 'z')\n",
    "    cleanline = cleanline.replace('xc3x86', 'Ã†')\n",
    "    return cleanline\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "# dictionary of dictionaries:\n",
    "# key = alphabet section     #value = empty dictionary for word counts\n",
    "alpha_dictionary = {\"A\":{}, \"B\":{}, \"C\":{}, \"D\":{}, \"E\":{}, \"F\":{}, \"G\":{}, \"H\":{}, \"I\":{}, \"K\":{}}\n",
    "\n",
    "#dictionary of page numbers:\n",
    "pages = 0\n",
    "#key = alphabet section      #value = empty 'pages' variable\n",
    "page_counter = {\"A\": pages, \"B\": pages, \"C\": pages, \"D\": pages, \"E\": pages, \"F\": pages, \"G\": pages, \"H\": pages, \"I\": pages, \"K\": pages}\n",
    "\n",
    "import csv\n",
    "\n",
    "#define total counts text file outfile\n",
    "outfile_total_count = open(\"volume1_counts.txt\", 'w', encoding=\"UTF-8\")\n",
    "\n",
    "#open full text of dictionary                                   ## LISTS OF LINES AND WORDS ##\n",
    "infile = open('johnson_volume1.txt','rb')\n",
    "text = str(infile.read())\n",
    "infile.close()\n",
    "\n",
    "# split into lines\n",
    "lines_list = text.split('\\\\n')\n",
    "# print(\"success: split into lines\")\n",
    "\n",
    "# clean lines\n",
    "for line in lines_list:\n",
    "     clean = clean_line(line)\n",
    "#     clean_words = clean.split()\n",
    "# print(\"success clean words\")\n",
    "\n",
    "\n",
    "#define current alphabet letter section\n",
    "alpha_sect = 65\n",
    "\n",
    "#for loop over words\n",
    "\n",
    "for line in lines_list:\n",
    "    line = line.lower()\n",
    "    clean_words = clean_line(line).split()\n",
    "    for word in clean_words:\n",
    "        if word == 'alphasectionend':\n",
    "            #write dictionary contents to CSV                   ## CSV COUNT ##\n",
    "            with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts.csv\", 'w', newline = '', encoding=\"UTF-8\") as outfile_csv:\n",
    "                filewriter = csv.writer(outfile_csv, delimiter=',')\n",
    "                filewriter.writerow(['word', 'count'])\n",
    "                for pair in alpha_dictionary[chr(alpha_sect)].items():\n",
    "                    label = pair[0]\n",
    "                    count = pair[1]\n",
    "                    row = [label, count]\n",
    "                    filewriter.writerow(row)\n",
    "\n",
    "        #evaluate CSV file to find shakespeare counts           ## SHAKESPEARE COUNT ##\n",
    "            with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts.csv\", 'r', encoding=\"UTF-8\") as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                total_count = 0\n",
    "                other_count = 0\n",
    "                misc_list = []\n",
    "                for row in csv_reader:\n",
    "                    if \"shakes\" in row[0]:\n",
    "                        total_count = total_count + int(row[1])\n",
    "                    elif \"count\" in row[1]:\n",
    "                        misc_list.append(row[1])\n",
    "                    else:\n",
    "                        other_count = other_count + int(row[1])\n",
    "\n",
    "            #print count results to text file\n",
    "            counts_statement = (\"There are \" + str(page_counter[chr(alpha_sect)]) + \" pages and \" + str(total_count) + \" Shakespeare citations in the \" + str(chr(alpha_sect)) + \" section.\")\n",
    "            # print(counts_statement)\n",
    "            print(counts_statement, file=outfile_total_count)\n",
    "\n",
    "            #redefine alpha_sect\n",
    "            if alpha_sect == 73:\n",
    "                alpha_sect = alpha_sect + 2\n",
    "            else:\n",
    "                alpha_sect = alpha_sect + 1\n",
    "        \n",
    "        #adding to page count\n",
    "        elif word == 'classpagenum':\n",
    "            page_counter[chr(alpha_sect)] = page_counter[chr(alpha_sect)] + 1\n",
    "            \n",
    "        #adding words and counts to dictionary\n",
    "        else:                                                   ## DICTIONARY COUNT ##\n",
    "            if word not in alpha_dictionary[chr(alpha_sect)]:   \n",
    "                alpha_dictionary[chr(alpha_sect)][word] = 1\n",
    "                # print(alpha_dictionary[chr(alpha_sect)])\n",
    "            else:\n",
    "                alpha_dictionary[chr(alpha_sect)][word] += 1\n",
    "\n",
    "outfile_csv.close()\n",
    "csv_file.close()\n",
    "outfile_total_count.close()\n",
    "\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
