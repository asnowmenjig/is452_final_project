{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success clean words\n",
      "['bd', 'i', 'c', 't', 'i', 'o', 'n', 'a', 'r', 'y']\n",
      "{'bd': 1}\n",
      "{'bd': 1, 'i': 1}\n",
      "{'bd': 1, 'i': 1, 'c': 1}\n",
      "{'bd': 1, 'i': 1, 'c': 1, 't': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 1, 'o': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 1, 'o': 1, 'n': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 1, 'o': 1, 'n': 1, 'a': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 1, 'o': 1, 'n': 1, 'a': 1, 'r': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 1, 'o': 1, 'n': 1, 'a': 1, 'r': 1, 'y': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 1, 'o': 1, 'n': 1, 'a': 1, 'r': 1, 'y': 1, 'alphasectendnalphasectendno': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 1, 'o': 1, 'n': 1, 'a': 1, 'r': 1, 'y': 1, 'alphasectendnalphasectendno': 1, 'f': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 2, 'o': 1, 'n': 1, 'a': 1, 'r': 1, 'y': 1, 'alphasectendnalphasectendno': 1, 'f': 1, 'h': 1}\n",
      "{'bd': 1, 'i': 2, 'c': 1, 't': 2, 'o': 1, 'n': 1, 'a': 1, 'r': 1, 'y': 1, 'alphasectendnalphasectendno': 1, 'f': 1, 'h': 1, 'e': 1}\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "##### PROGRAM FOR VOLUME 1 #####\n",
    "\n",
    "import string\n",
    "\n",
    "def clean_line(line_str):\n",
    "    cleanline = line_str.lower()\n",
    "    for punc in string.punctuation:\n",
    "         cleanline = cleanline.replace(punc, \"\")\n",
    "#    cleanline = cleanline.replace(\"rn\",\" \")\n",
    "    cleanline = cleanline.replace(\"xc2xb\", \"o\")\n",
    "    cleanline = cleanline.replace(\"xc2xba\", \"o\")\n",
    "    cleanline = cleanline.replace(\"xc3x97\", \"x\")\n",
    "    cleanline = cleanline.replace(\"xc3xa\", \"a\")\n",
    "    cleanline = cleanline.replace(\"xc3xa1\", 'a')\n",
    "    cleanline = cleanline.replace('xc3xa2', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa4', 'a')\n",
    "    cleanline = cleanline.replace('xc4x83', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa3', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa5', 'a')\n",
    "    cleanline = cleanline.replace('xc4x81', 'a')\n",
    "    cleanline = cleanline.replace('xc4x85', 'a')\n",
    "    cleanline = cleanline.replace('xc4x87', 'c')\n",
    "    cleanline = cleanline.replace('xc4x8d', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa7', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa8', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa9', 'e')\n",
    "    cleanline = cleanline.replace('xc3xab', 'e')\n",
    "    cleanline = cleanline.replace('xc4x93', 'e')\n",
    "    cleanline = cleanline.replace('xc4x99', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa', 'e')\n",
    "    cleanline = cleanline.replace('xc4x9f', 'g')\n",
    "    cleanline = cleanline.replace('xc3xad', 'i')\n",
    "    cleanline = cleanline.replace('xc3xac', 'i')\n",
    "    cleanline = cleanline.replace('xc5x84', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb1', 'n')\n",
    "    cleanline = cleanline.replace('xc5x88', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb3', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb6', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb8', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb2', 'o')\n",
    "    cleanline = cleanline.replace('xc5x99', 'r')\n",
    "    cleanline = cleanline.replace('xc5xa1', 's')\n",
    "    cleanline = cleanline.replace(\"xc5xbf\", \"s\")\n",
    "    cleanline = cleanline.replace('xc5x9b', 's')\n",
    "    cleanline = cleanline.replace('xc5x9f', 's')\n",
    "    cleanline = cleanline.replace('xc5xa3', 't')\n",
    "    cleanline = cleanline.replace('xc3xbc', 'u')\n",
    "    cleanline = cleanline.replace('xc3xba', 'u')\n",
    "    cleanline = cleanline.replace('xc5xab', 'u')\n",
    "    cleanline = cleanline.replace('xc5xba', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbc', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbe', 'z')\n",
    "    cleanline = cleanline.replace('xc3x86', 'Ã†')\n",
    "    return cleanline\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "# dictionary to hold dictionaries of counts\n",
    "alpha_dictionary = {\"A\":{}, \"B\":{}, \"C\":{}, \"D\":{}, \"E\":{}, \"F\":{}, \"G\":{}, \"H\":{}, \"I\":{}, \"K\":{}}\n",
    "\n",
    "#define CSV outfile\n",
    "import csv\n",
    "#outfile_csv = open(\"tester_alpha_A.csv\" , 'r+', newline = '', encoding=\"UTF-8\")\n",
    "\n",
    "#define total counts text file outfile\n",
    "outfile_total_count = open(\"volume1_shakespeare_counts.txt\", 'w', encoding=\"UTF-8\")\n",
    "\n",
    "#open full text of dictionary                           ## LISTS OF LINES AND WORDS ##\n",
    "infile = open('johnson_v1_tester.txt','rb')\n",
    "text = str(infile.read())\n",
    "infile.close()\n",
    "\n",
    "# split into lines\n",
    "lines_list = text.split(\"\\\\n\")\n",
    "print(\"success: split into lines\")\n",
    "\n",
    "# clean lines\n",
    "for line in lines_list:\n",
    "     clean = clean_line(line)\n",
    "#     clean_words = clean.split()\n",
    "print(\"success cleaned lines\")\n",
    "\n",
    "\n",
    "#define current alphabet letter section\n",
    "alpha_sect = 65\n",
    "\n",
    "#for loop over words\n",
    "\n",
    "for line in lines_list:\n",
    "    line = line.lower()\n",
    "    clean_words = clean_line(line).split()\n",
    "    for word in clean_words:\n",
    "        if word == \"alphasectionend\":\n",
    "        #write dictionary contents to CSV                           ## CSV COUNT ##\n",
    "            with open(\"tester_alpha_\" + str(chr(alpha_sect)) + \".csv\", 'w', newline = '', encoding=\"UTF-8\") as outfile_csv:\n",
    "                filewriter = csv.writer(outfile_csv, delimiter=',')\n",
    "                filewriter.writerow(['word', 'count'])\n",
    "                for pair in alpha_dictionary[chr(alpha_sect)].items():\n",
    "                    label = pair[0]\n",
    "                    count = pair[1]\n",
    "                    row = [label, count]\n",
    "                    filewriter.writerow(row)\n",
    "            print(\"success: write to \" + str(chr(alpha_sect)) + \" csv\")\n",
    "\n",
    "        #evaluate CSV file to find shakespeare counts               ## SHAKESPEARE COUNT ##\n",
    "            with open(\"tester_alpha_\" + str(chr(alpha_sect)) + \".csv\", 'r', encoding=\"UTF-8\") as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                total_count = 0\n",
    "                other_count = 0\n",
    "                misc_list = []\n",
    "                for row in csv_reader:\n",
    "                    if \"shakes\" in row[0]:\n",
    "                        total_count = total_count + int(row[1])\n",
    "                    elif \"count\" in row[1]:\n",
    "                        misc_list.append(row[1])\n",
    "                    else:\n",
    "                        other_count = other_count + int(row[1])\n",
    "\n",
    "        #print results to text file\n",
    "            citations_statement = (\"There are \" + str(total_count) + \" Shakespeare citations in the \" + str(chr(alpha_sect)) + \" section.\")\n",
    "            print(citations_statement)\n",
    "            print(citations_statement, file=outfile_total_count)\n",
    "\n",
    "        #redefine alpha_sect\n",
    "            if alpha_sect == 73:\n",
    "                alpha_sect = alpha_sect + 2\n",
    "        else:\n",
    "            alpha_sect = alpha_sect + 1\n",
    "\n",
    "    else:\n",
    "        if word not in alpha_dictionary[chr(alpha_sect)]:       ## DICTIONARY COUNT ##\n",
    "            alpha_dictionary[chr(alpha_sect)][word] = 1\n",
    "            print(alpha_dictionary[chr(alpha_sect)])\n",
    "        else:\n",
    "            alpha_dictionary[chr(alpha_sect)][word] += 1\n",
    "\n",
    "outfile_total_count.close()\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
