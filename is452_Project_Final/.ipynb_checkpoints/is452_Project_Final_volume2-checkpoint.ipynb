{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing...\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "#VOLUME 2 (file: johnson_v2_tester.txt)\n",
    "# L = lines 1 to 15051              #page np-57\n",
    "# M = lines 15052 to 35219          #page 58-162\n",
    "# N = lines 35220 to 42065          #page 163-199\n",
    "# O = lines 42066 to 52444          #page 200-255\n",
    "# P = lines 52445 to 86621          #page 256-256\n",
    "# Q = lines 86622 to 89152\n",
    "# R = lines 89153 to 109975         #page 256-287\n",
    "# S = lines 109976 to 163666        #page 288-np\n",
    "# T = lines 163667 to 184884        #page np-np\n",
    "# V/U = lines 184885 to 207055\n",
    "# W = lines 207056 to 221677\n",
    "# X = lines 221678 to 221680\n",
    "# Y = lines 221681 to 222794\n",
    "# Z = lines 222795 to 223069\n",
    "\n",
    "##### PROGRAM FOR VOLUME 2 #####\n",
    "\n",
    "print(\"Executing...\")\n",
    "\n",
    "import string\n",
    "\n",
    "def clean_line(line_str):\n",
    "    cleanline = line_str.lower()\n",
    "    for punc in string.punctuation:\n",
    "         cleanline = cleanline.replace(punc, \"\")\n",
    "    cleanline = cleanline.replace('xc2xb', \"o\")\n",
    "    cleanline = cleanline.replace(\"xc2xba\", \"o\")\n",
    "    cleanline = cleanline.replace(\"xc3x97\", \"x\")\n",
    "    cleanline = cleanline.replace(\"xc3xa\", \"a\")\n",
    "    cleanline = cleanline.replace(\"xc3xa1\", 'a')\n",
    "    cleanline = cleanline.replace('xc3xa2', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa4', 'a')\n",
    "    cleanline = cleanline.replace('xc4x83', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa3', 'a')\n",
    "    cleanline = cleanline.replace('xc3xa5', 'a')\n",
    "    cleanline = cleanline.replace('xc4x81', 'a')\n",
    "    cleanline = cleanline.replace('xc4x85', 'a')\n",
    "    cleanline = cleanline.replace('xc4x87', 'c')\n",
    "    cleanline = cleanline.replace('xc4x8d', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa7', 'c')\n",
    "    cleanline = cleanline.replace('xc3xa8', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa9', 'e')\n",
    "    cleanline = cleanline.replace('xc3xab', 'e')\n",
    "    cleanline = cleanline.replace('xc4x93', 'e')\n",
    "    cleanline = cleanline.replace('xc4x99', 'e')\n",
    "    cleanline = cleanline.replace('xc3xa', 'e')\n",
    "    cleanline = cleanline.replace('xc4x9f', 'g')\n",
    "    cleanline = cleanline.replace('xc3xad', 'i')\n",
    "    cleanline = cleanline.replace('xc3xac', 'i')\n",
    "    cleanline = cleanline.replace('xc5x84', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb1', 'n')\n",
    "    cleanline = cleanline.replace('xc5x88', 'n')\n",
    "    cleanline = cleanline.replace('xc3xb3', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb6', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb8', 'o')\n",
    "    cleanline = cleanline.replace('xc3xb2', 'o')\n",
    "    cleanline = cleanline.replace('xc5x99', 'r')\n",
    "    cleanline = cleanline.replace('xc5xa1', 's')\n",
    "    cleanline = cleanline.replace('xc5xbf', 's')\n",
    "    cleanline = cleanline.replace('xc5x9b', 's')\n",
    "    cleanline = cleanline.replace('xc5x9f', 's')\n",
    "    cleanline = cleanline.replace('xc5xa3', 't')\n",
    "    cleanline = cleanline.replace('xc3xbc', 'u')\n",
    "    cleanline = cleanline.replace('xc3xba', 'u')\n",
    "    cleanline = cleanline.replace('xc5xab', 'u')\n",
    "    cleanline = cleanline.replace('xc5xba', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbc', 'z')\n",
    "    cleanline = cleanline.replace('xc5xbe', 'z')\n",
    "    cleanline = cleanline.replace('xc3x86', 'Ã†')\n",
    "    return cleanline\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "# dictionary of dictionaries:\n",
    "# key = alphabet section     #value = empty dictionary for word counts\n",
    "alpha_dictionary = {\"L\":{}, \"M\":{}, \"N\":{}, \"O\":{}, \"P\":{}, \"Q\":{}, \"R\":{}, \"S\":{}, \"T\":{}, \"U\":{}, \"W\":{}, \"X\":{}, \"Y\":{}, \"Z\":{}}\n",
    "\n",
    "\n",
    "#dictionary of page numbers:\n",
    "pages = 0\n",
    "#key = alphabet section      #value = empty 'pages' variable\n",
    "page_counter = {\"L\":pages, \"M\":pages, \"N\":pages, \"O\":pages, \"P\":pages, \"Q\":pages, \"R\":pages, \"S\":pages, \"T\":pages, \"U\":pages, \"W\":pages, \"X\":pages, \"Y\":pages, \"Z\":pages}\n",
    "\n",
    "import csv\n",
    "\n",
    "#define total counts text file outfile\n",
    "outfile_total_count = open(\"volume2_counts.txt\", 'w', encoding=\"UTF-8\")\n",
    "\n",
    "#open full text of dictionary                                   ## LISTS OF LINES AND WORDS ##\n",
    "infile = open('johnson_volume2.txt','rb')\n",
    "text = str(infile.read())\n",
    "infile.close()\n",
    "\n",
    "# split into lines\n",
    "lines_list = text.split('\\\\n')\n",
    "# print(\"success: split into lines\")\n",
    "\n",
    "# clean lines\n",
    "for line in lines_list:\n",
    "     clean = clean_line(line)\n",
    "#     clean_words = clean.split()\n",
    "# print(\"success clean words\")\n",
    "\n",
    "\n",
    "#define current alphabet letter section\n",
    "alpha_sect = 76\n",
    "\n",
    "#for loop over words\n",
    "\n",
    "for line in lines_list:\n",
    "    line = line.lower()\n",
    "    clean_words = clean_line(line).split()\n",
    "    for word in clean_words:\n",
    "        if word == 'alphasectionend':\n",
    "            #write dictionary contents to CSV                   ## CSV COUNT ##\n",
    "            with open(\"tester_alpha_\" + str(chr(alpha_sect)) + \".csv\", 'w', newline = '', encoding=\"UTF-8\") as outfile_csv:\n",
    "                filewriter = csv.writer(outfile_csv, delimiter=',')\n",
    "                filewriter.writerow(['word', 'count'])\n",
    "                for pair in alpha_dictionary[chr(alpha_sect)].items():\n",
    "                    label = pair[0]\n",
    "                    count = pair[1]\n",
    "                    row = [label, count]\n",
    "                    filewriter.writerow(row)\n",
    "\n",
    "        #evaluate CSV file to find shakespeare counts           ## SHAKESPEARE COUNT ##\n",
    "            with open(\"Letter_\" + str(chr(alpha_sect)) + \"_counts.csv\", 'r', encoding=\"UTF-8\") as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                total_count = 0\n",
    "                other_count = 0\n",
    "                misc_list = []\n",
    "                for row in csv_reader:\n",
    "                    if \"shakes\" in row[0]:\n",
    "                        total_count = total_count + int(row[1])\n",
    "                    elif \"count\" in row[1]:\n",
    "                        misc_list.append(row[1])\n",
    "                    else:\n",
    "                        other_count = other_count + int(row[1])\n",
    "\n",
    "            #print results to text file\n",
    "            counts_statement = (\"There are \" + str(page_counter[chr(alpha_sect)]) + \" pages and \" + str(total_count) + \" Shakespeare citations in the \" + str(chr(alpha_sect)) + \" section.\")\n",
    "            # print(counts_statement)\n",
    "            print(counts_statement, file=outfile_total_count)\n",
    "\n",
    "            #redefine alpha_sect\n",
    "            if alpha_sect == 85:\n",
    "                alpha_sect = alpha_sect + 2\n",
    "            else:\n",
    "                alpha_sect = alpha_sect + 1\n",
    "                \n",
    "        #adding to page count\n",
    "        elif word == 'classpagenum':\n",
    "            page_counter[chr(alpha_sect)] = page_counter[chr(alpha_sect)] + 1\n",
    "\n",
    "        #adding words and counts to dictionary\n",
    "        else:\n",
    "            if word not in alpha_dictionary[chr(alpha_sect)]:   ## DICTIONARY COUNT ##\n",
    "                alpha_dictionary[chr(alpha_sect)][word] = 1\n",
    "                #print(alpha_dictionary[chr(alpha_sect)])\n",
    "            else:\n",
    "                alpha_dictionary[chr(alpha_sect)][word] += 1\n",
    "\n",
    "outfile_total_count.close()\n",
    "csv_file.close()\n",
    "outfile_total_count.close()\n",
    "\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
